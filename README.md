# Sign-Flow

# ğŸ¤Ÿ Sign Flow: Real-Time Sign Language to Speech Interface

*Bridging gestures to voice â€” and voice to gestures â€” with AI-powered ASL interpretation.*

---

## ğŸ“Œ Overview

**Sign Flow** is a real-time, bidirectional ASL interpretation system that enables:

- âœ‹ Translating **ASL gestures** into **text and speech**
- ğŸ¤ Converting **spoken audio** into **corresponding ASL video segments**

Itâ€™s built using deep learning, computer vision, speech recognition, and real-time video rendering â€” delivering inclusive communication in both directions.

---

## ğŸš€ Features

### ğŸ¥ Sign-to-Text + Speech

- Live **ASL gesture recognition** using webcam input
- **CNN model** trained on ASL alphabet dataset with 95%+ accuracy
- **MediaPipe Hands** for landmark-based cropping
- **Prediction buffering** for consistency
- **GPT & TTS integration** to form and speak full sentences

### ğŸ” Audio-to-ASL Video

- Input a **spoken phrase** via microphone or file
- Extracted **keywords** trigger matching **ASL gesture videos**
- Dynamically stream matching video clips from `data/sign_videos/` to the frontend

---

## ğŸ› ï¸ Tech Stack

| Layer        | Technologies                                       |
|--------------|----------------------------------------------------|
| Frontend     | React, Tailwind CSS, MediaPipe Hands, CameraUtils |
| Backend      | Python, FastAPI, PyTorch, TorchVision, SpeechRecognition |
| ML Model     | ResNet18 CNN (custom-trained on ASL dataset)       |
| Audio        | SpeechRecognition, PyDub, MoviePy, ffmpeg          |
| Video        | HTML5 video rendering from static ASL video clips  |
| Extras       | GPT for NLP-based text enhancement + sentence prediction |

---

## ğŸ“‚ Folder Structure
```
sign-flow/
â”‚
â”œâ”€â”€ backend/                             # FastAPI backend for ASL recognition
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ model.py                     # PyTorch model loading + prediction
â”‚   â”‚   â”œâ”€â”€ hand_detector.py            # MediaPipe hand cropping logic
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ asl_cnn_model.pt            # Trained ASL CNN model
â”‚   â”œâ”€â”€ main.py                          # FastAPI app (predict endpoint)
â”‚   â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ audio_to_sign/                      # Audio to ASL Video module
|   |â”€â”€ data/
â”‚   |     â”œâ”€â”€ sign_videos/                   # ASL gesture videos (e.g., hello.mp4, thankyou.mp4)
â”‚   |     â””â”€â”€ samples/ 
â”‚   â”œâ”€â”€ mic_to_audio/
â”‚   â”‚   â”œâ”€â”€ recorded_audio.wav
â”‚   â”‚   â”œâ”€â”€ temp_audio.wav
â”‚   â”‚   â””â”€â”€ react_temp_audio.wav
â”‚   â”œâ”€â”€ final_path/
â”‚   â”‚   â””â”€â”€ matched_path.txt
â”‚   â”œâ”€â”€ text_to_sign/
â”‚   â”‚   â”œâ”€â”€ sign_transcription.txt
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ speech_to_text.py           # Converts audio â†’ text
â”‚   â”‚   â”œâ”€â”€ sign_mapping.py             # Maps text â†’ video paths
â”‚   â”‚   â””â”€â”€ text_to_sign.py             # Core logic: sentence â†’ sign video sequence
â”‚   â”œâ”€â”€ fastapi_send_audio.py           # Optional: Audio upload + video stream API
â”‚   â”œâ”€â”€ app.py                          # Stream ASL videos for input sentence
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ asl-app/                            # React frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ manifest.json
â”‚   â”‚   â””â”€â”€ logo512.png (etc.)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â”œâ”€â”€ AudioRecorder.js            # Audio recorder component
â”‚   â”‚   â”œâ”€â”€ VideoPlayer.js              # ASL video stream player
â”‚   â”‚   â”œâ”€â”€ video_to_text.js            # Hand gesture â†’ prediction React component
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”‚       â”œâ”€â”€ App.css
â”‚   â”‚       â”œâ”€â”€ AudioRecorder.css
â”‚   â”‚       â””â”€â”€ VideoPlayer.css
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md

```


## âš™ï¸ Setup Instructions

### ğŸ”¹ Backend (FastAPI + PyTorch + Audio)
```bash
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload
```


### ğŸ”¹ Frontend (React + Tailwind)

cd frontend
npm install
npm run dev



### ğŸ§ª Examples
### ğŸ–ï¸ ASL Gesture Input

{
  "prediction": {
    "prediction": "H",
    "confidence": 97.35
  }
}


### ğŸ”Š Audio-to-ASL Input
### Input: "Thank you very much"
### â†’ Plays: data/sign_videos/thank.mp4 + you.mp4


### ğŸ“Š Dataset
- ASL Alphabet Dataset (Kaggle)

- Custom image captures using webcam

- how2Sign videos for common words stored in data/sign_videos/

### ğŸ”® Future Enhancements
- âœ‹ Full-word gesture detection from landmarks

- ğŸ§  Transformer model for sequential sign recognition

- ğŸ¤ Live microphone transcription to video

- â˜ï¸ Cloud deployment (e.g., HuggingFace, Vercel, or Streamlit)

# ğŸ§‘â€ğŸ’» Author
- Himanshu & Sourav
- Computer Science Graduate | UNC Charlotte
- [GitHub](https://github.com/garud24) â€¢ [LinkedIn](https://www.linkedin.com/in/himanshu-garud/)

